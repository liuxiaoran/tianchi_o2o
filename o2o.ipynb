{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "off_train= pd.read_csv(\"data/ccf_offline_stage1_train.csv\",header=0) # 跳过header\n",
    "online_train = pd.read_csv(\"data/ccf_online_stage1_train.csv\",header=0)\n",
    "off_predict =pd.read_csv(\"data/ccf_offline_stage1_test_revised.csv\",header=0)\n",
    "off_train.columns = [\"user_id\",\"merchant_id\",\"coupon_id\",\"discount_rate\",\"distance\",\"date_received\",\"date\"]\n",
    "online_train.columns = [\"user_id\",\"merchant_id\",\"action\",\"coupon_id\",\"discount_rate\",\"date_received\",\"date\"]\n",
    "off_predict.columns = [\"user_id\",\"merchant_id\",\"coupon_id\",\"discount_rate\",\"distance\",\"date_received\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 7)\n",
      "(0, 7)\n",
      "off_train online_train 没有date_received 和 data 同时为NULL 的情况\n",
      "off_train记录数目：1754884\n",
      "off_train领取优惠券数量：1053282\n",
      "off_train优惠券种类： 9738\n",
      "(17888, 7)\n",
      "一个coupon_id 可能对应多个merchat_id\n",
      "off_train用户个数：539438\n",
      "date_received区间：20160101 到 20160615\n",
      "date 区间：20160101 到 20160630\n"
     ]
    }
   ],
   "source": [
    "print off_train[((off_train.date_received=='null') & (off_train.date=='null'))].shape\n",
    "print online_train[((online_train.date_received=='null') & (online_train.date=='null'))].shape\n",
    "print \"off_train online_train 没有date_received 和 data 同时为NULL 的情况\"\n",
    "\n",
    "print \"off_train记录数目：\"+str(off_train.shape[0])\n",
    "print \"off_train领取优惠券数量：\"+str(off_train[(off_train.date_received!='null')].shape[0])\n",
    "print \"off_train优惠券种类： \"+str(off_train[off_train.coupon_id!='null'].coupon_id.value_counts().shape[0])\n",
    "print off_train.drop_duplicates([\"merchant_id\",\"coupon_id\"]).shape\n",
    "\n",
    "# def f(s):\n",
    "#     return pd.Series({ 'n':s[\"merchant_id\"].drop_duplicates().shape[0]})\n",
    "# off_train.groupby([\"coupon_id\"]).apply(f)\n",
    "print \"一个coupon_id 可能对应多个merchat_id\"\n",
    "\n",
    "\n",
    "print \"off_train用户个数：\"+str(off_train.user_id.value_counts().shape[0])\n",
    "print \"date_received区间：\"+ str(off_train[off_train[\"date_received\"]!=\"null\"].date_received.min()) +\" 到 \"+str(off_train[off_train[\"date_received\"]!=\"null\"].date_received.max())\n",
    "print \"date 区间：\" +str(off_train[off_train[\"date\"]!=\"null\"].date.min())+\" 到 \"+ str(off_train[off_train[\"date\"]!=\"null\"].date.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701602"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_train.discount_rate.value_counts()[\"null\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off_predict 有76309用户\n",
      "off_predict 有43155用户 与 online_train用户有交集\n",
      "off_predict 有76307用户 与 off_train用户有交集\n",
      "\n",
      "off_predict有1559商家\n",
      "off_predict 有0商家 与 online_train 商家有交集\n",
      "off_predict 有1558商家 与 off_train 商家有交集\n",
      "\n",
      "off_predict有2050优惠券\n",
      "off_predict有1269优惠券　与 off_train 优惠券有交集\n"
     ]
    }
   ],
   "source": [
    "off_train_user_id = off_train.user_id.drop_duplicates()\n",
    "off_predict_user_id = off_predict.user_id.drop_duplicates()\n",
    "online_train_user_id = online_train.user_id.drop_duplicates()\n",
    "off_train_user_id.index = off_train_user_id.values\n",
    "off_predict_user_id.index = off_predict_user_id.values\n",
    "online_train_user_id.index = online_train_user_id.values\n",
    "\n",
    "print \"off_predict 有\"+str (off_predict_user_id.size)+\"用户\"\n",
    "print \"off_predict 有\"+str(off_predict_user_id.index.intersection(online_train_user_id.index).shape[0])+\"用户 与 online_train用户有交集\"\n",
    "print \"off_predict 有\"+str(off_predict_user_id.index.intersection(off_train_user_id.index).shape[0])+\"用户 与 off_train用户有交集\"\n",
    "print \n",
    "\n",
    "off_train_merchant_id  = off_train.merchant_id.drop_duplicates()\n",
    "off_predict_merchant_id = off_predict.merchant_id.drop_duplicates()\n",
    "online_train_merchant_id = online_train.merchant_id.drop_duplicates()\n",
    "off_train_merchant_id.index = off_train_merchant_id.values\n",
    "off_predict_merchant_id.index = off_predict_merchant_id.values\n",
    "online_train_merchant_id.index = online_train_merchant_id.values\n",
    "\n",
    "print  \"off_predict有\"+str(off_predict_merchant_id.size)+\"商家\"\n",
    "print  \"off_predict 有\"+str(off_predict_merchant_id.index.intersection(online_train_merchant_id.index).shape[0])+\"商家 与 online_train 商家有交集\"\n",
    "print  \"off_predict 有\"+str(off_predict_merchant_id.index.intersection(off_train_merchant_id.index).shape[0])+\"商家 与 off_train 商家有交集\"\n",
    "print\n",
    "\n",
    "off_predict_coupon_id = off_predict.coupon_id.drop_duplicates()\n",
    "off_train_coupon_id = off_train.coupon_id.drop_duplicates()\n",
    "off_predict_coupon_id.index = off_predict_coupon_id.values\n",
    "off_train_coupon_id.index = off_train_coupon_id.values\n",
    "\n",
    "print \"off_predict有\"+ str(off_predict_coupon_id.size)+\"优惠券\"\n",
    "print  \"off_predict有\"+str(off_predict_coupon_id.index.intersection(off_train_merchant_id.index).shape[0])+\"优惠券　与 off_train 优惠券有交集\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#划分数据集为训练集和测试集\n",
    "# 特征窗: feature 和 标签窗: dataset\n",
    "dataset1 = off_train[((off_train.date_received>=\"20160414\")&(off_train.date_received<=\"20160514\"))]\n",
    "feature1 = off_train[(((off_train.date>=\"20160101\" ) & (off_train.date<=\"20160414\")) | ((off_train.date==\"null\") &(off_train.date_received>=\"20160101\")&(off_train.date_received<=\"20160414\")))]\n",
    "\n",
    "dataset2 = off_train[(off_train.date_received>=\"20160514\") & (off_train.date_received<=\"20160615\")]\n",
    "feature2 = off_train[((off_train.date>=\"20160201\")  & (off_train.date<=\"20160514\")) |( (off_train.date==\"null\")  & (off_train.date_received>=\"20160201\") &(off_train.date_received<=\"20160514\"))]\n",
    "\n",
    "dataset3= off_predict\n",
    "feature3 = off_train[((off_train.date>=\"20160315\")  & (off_train.date<=\"20160701\")) |( (off_train.date==\"null\")  & (off_train.date_received>=\"20160315\") &(off_train.date_received<=\"20160701\"))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160712\n",
      "20160712\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "(\"can't compare datetime.timedelta to int\", u'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-8a20dea34478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mt7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"str\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mt7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"str\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mt7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"day_gap_before\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mt7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dates\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"date_received\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday_gap_before\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mt7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4150\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4246\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4247\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4248\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4249\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4250\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-8a20dea34478>\u001b[0m in \u001b[0;36mday_gap_before\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mgap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mgap\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mgaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: (\"can't compare datetime.timedelta to int\", u'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "#for dataset3\n",
    "from datetime import date\n",
    "t = dataset3[[\"user_id\"]]\n",
    "t[\"this_month_user_receive_all_coupon\"]=1\n",
    "t=t.groupby([\"user_id\"]).agg(\"sum\").reset_index()\n",
    " \n",
    "\n",
    "t1 = dataset3[[\"user_id\",\"coupon_id\"]]\n",
    "t1[\"this_month_user_receive_same_coupon\"]=1\n",
    "t1= t1.groupby([\"user_id\",\"coupon_id\"]).agg(\"sum\").reset_index()\n",
    " \n",
    "\n",
    "t2= dataset3[[\"user_id\",\"coupon_id\",\"date_received\"]]\n",
    "t2.date_received = t2.date_received.astype('str') # 必须得astype(str)转化为string,默认是object 类型，后面要使用join 对于字符串连接\n",
    "t2  =t2[(t2.date_received !=\"null\")]\n",
    "t2 = t2.groupby(['user_id','coupon_id']).agg(lambda x:':'.join(x)).reset_index()\n",
    "def f(s):\n",
    "    return len(s.split(\":\"))\n",
    "t2[\"receive_number\"] = t2.date_received.apply(f)\n",
    "t2= t2[(t2.receive_number>1)]\n",
    "\n",
    "    \n",
    "t2[\"max_date_received\"]=t2.date_received.apply(lambda x: max([ int(d) for d in x.split(\":\")])  )\n",
    "t2[\"min_date_received\"]=t2.date_received.apply(lambda x:min([int(d) for d in x.split(\":\")]) )\n",
    "t2=t2[[\"user_id\",\"coupon_id\",\"max_date_received\",\"min_date_received\"]]\n",
    "\n",
    "t3= dataset3[[\"user_id\",\"coupon_id\",\"date_received\"]]\n",
    "t3=pd.merge(t3,t2,on=[\"user_id\",\"coupon_id\"],how=\"left\")\n",
    "t3[\"this_month_user_receive_same_coupon_lastone\"]=t3[\"max_date_received\"]-t3[\"date_received\"]\n",
    "t3[\"this_month_user_receive_same_coupon_firstone\"]=t3[\"date_received\"]-t3[\"min_date_received\"]\n",
    "\n",
    "def is_firstlastone(x):\n",
    "    if x==0:\n",
    "        return 1\n",
    "    elif x>0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # 仅仅收到一次\n",
    "t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "\n",
    "\n",
    "t4=dataset3[[\"user_id\",\"date_received\"]]\n",
    "t4[\"this_day_user_receive_all_coupon_count\"]=1\n",
    "t4= t4.groupby([\"user_id\",\"date_received\"]).agg(\"sum\").reset_index()\n",
    "\n",
    "t5 = dataset3[[\"user_id\",\"coupon_id\",\"date_received\"]]\n",
    "t5[\"this_day_user_receive_same_coupon_count\"]=1\n",
    "t5=t5.groupby([\"user_id\",\"coupon_id\",\"date_received\"]).agg(\"sum\").reset_index()\n",
    "\n",
    "t6= dataset3[[\"user_id\",\"coupon_id\",\"date_received\"]]\n",
    "t6.date_received = t6.date_received.astype('str')\n",
    "t6=t6.groupby([\"user_id\",\"coupon_id\"]).agg(lambda x : \":\".join(x)).reset_index()\n",
    "t6.rename(columns={\"date_received\":\"dates\"},inplace=True)\n",
    "\n",
    "\n",
    "t7= dataset3[[\"user_id\",\"coupon_id\",\"date_received\"]]\n",
    "t7= pd.merge(t7,t6, on=[\"user_id\",\"coupon_id\"],how=\"left\")\n",
    "t7= t7.head(10)\n",
    "def day_gap_before(s):\n",
    "    date_received = s[\"date_received\"]\n",
    "    dates = s[\"dates\"].split(\":\")\n",
    "    print date_received\n",
    "    gaps=[]\n",
    "    # date 类型可以加减操作\n",
    "    for d in dates:\n",
    "       \n",
    "        gap =( date(int(date_received[0:4]),int(date_received[4:6]), int (date_received[6:8])) - date(int(d[0:4]),int(d[4:6]), int (d[6:8]))     ).days  \n",
    "        if gap>0:\n",
    "            gaps.append(gap)\n",
    "    if (len(gaps)==0):\n",
    "        return -1\n",
    "    return min(gaps)\n",
    "\n",
    "t7.dates=t7.dates.astype(\"str\")\n",
    "t7.date_received=t7.date_received.astype(\"str\")\n",
    "t7[\"day_gap_before\"]= t7[[\"dates\",\"date_received\"]].apply(day_gap_before,axis = 1)\n",
    "print t7.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## coupon feature\n",
    "优惠比率:discount_rate ; 历史领取次数：receive_count; 销核次数：use_count; 销核比率：use_rate; 领取日期是周几：day_of_week; 领取日期是一个月第几天：day_of_month;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'null'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-413b3a2139c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# dataset1.use_rate = dataset1.use_count/dataset1.receive_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdataset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day_of_week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdataset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2294\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:66124)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-413b3a2139c0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# dataset1.use_rate = dataset1.use_count/dataset1.receive_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdataset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day_of_week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdataset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'null'"
     ]
    }
   ],
   "source": [
    "# dataset1\n",
    "# 优惠比率特征\n",
    "def cal_discount_rate(s):\n",
    "    s=str(s)\n",
    "    if s ==\"null\":\n",
    "        return np.NaN\n",
    "    else:\n",
    "        splited = s.split(\":\")\n",
    "        if len(splited)==1:\n",
    "            return float(splited[0])\n",
    "        else:\n",
    "            return 1- float(splited[1])/float(splited[0])\n",
    "dataset1[\"discount_rate\"] = dataset1.discount_rate.apply(cal_discount_rate)\n",
    "\n",
    "# # 历史领取次数\n",
    "# d =dataset1[[\"coupon_id\"]]\n",
    "# d[\"receive_count\"]=1\n",
    "# d2 = d.groupby([\"coupon_id\"]).agg(\"sum\").reset_index()\n",
    "# dataset1 = pd.merge(dataset1,d2,on=\"coupon_id\",how=\"left\")\n",
    "\n",
    "# # 销核次数\n",
    "# d=dataset1[[\"coupon_id\",\"date\",\"date_received\"]]\n",
    "# d2 =d[(d.date!=\"null\"  )& (d.date_received!=\"null\")]\n",
    "# d2[\"use_count\"]=1\n",
    "# d3= d2.groupby([\"coupon_id\"]).agg(\"sum\").reset_index()\n",
    "# dataset1 = pd.merge(dataset1,d2,on=\"coupon_id\",how=\"left\")\n",
    "\n",
    "# dataset1.use_rate = dataset1.use_count/dataset1.receive_count\n",
    "\n",
    "dataset1['day_of_week'] = dataset1.date_received.astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])))\n",
    "print dataset1.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    113635\n",
       "True          5\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3.user_id.isin([448]).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
